{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "152a2ef4",
   "metadata": {},
   "source": [
    "## Code for parameters grid:\n",
    "Here is reported the code for obtaining the grid of digital biomarkers (in this case we use resting-state PSD and FC quantitites) for various combinations of model biomarkers:\n",
    "\n",
    "References: \n",
    "\n",
    "[1] L. G. Amato, A. A. Vergani, M. Lassi, C. Fabbiani, S. Mazzeo, R. Burali, B. Nacmias, S. Sorbi, R. Mannella, A. Grippo, V. Bessi, A. Mazzoni, Personalized modeling of Alzheimerâ€™s disease progression estimates neurodegeneration severity from EEG recordings. Alzheimers Dement. Diagn. Assess. Dis. Monit. 16, e12526 (2024).\n",
    "\n",
    "[2] L. G. Amato, A. A. Vergani, M. Lassi, J. Carpaneto, S. Mazzeo, V. Moschini, R. Burali, G. Salvestrini, C. Fabbiani, G. Giacomucci, G. Galdo, C. Morinelli, F. Emiliani, M. Scarpino, S. Padiglioni, B. Nacmias, S. Sorbi, A. Grippo, V. Bessi, A. Mazzoni, Personalized brain models link cognitive decline progression to underlying synaptic and connectivity degeneration. Alzheimers Res. Ther. 17, 74 (2025)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8325a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online visualization.\n",
    "%pylab nbagg\n",
    "\n",
    "import sys\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Import tvb library.\n",
    "import numpy as np\n",
    "import tvb.simulator.lab as tvb\n",
    "from tvb.basic.neotraits.api import Final, List\n",
    "from tvb.simulator.lab import *\n",
    "from tvb.datatypes import graph\n",
    "from tvb.datatypes.time_series import TimeSeriesRegion \n",
    "from tvb.analyzers.info import sampen\n",
    "import tvb.simulator.plot.power_spectra_interactive as ps_int\n",
    "\n",
    "# Import a bunch of stuff to ease command line usage.\n",
    "from scipy.stats import entropy, chi2_contingency, circvar, pearsonr, ttest_ind\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, lfilter, freqz, hilbert, coherence, filtfilt\n",
    "from scipy.special import xlogy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def norma(arr, a=0, b=1):\n",
    "    \"\"\"\n",
    "    Normalizes the input array to the range [a, b].\n",
    "\n",
    "    Parameters:\n",
    "    arr (numpy.ndarray): Input array to be normalized.\n",
    "    a (float): Lower bound of the desired range.\n",
    "    b (float): Upper bound of the desired range.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The normalized array with values in the range [a, b].\n",
    "    \"\"\"\n",
    "    arr_min = np.min(arr)\n",
    "    arr_max = np.max(arr)\n",
    "    \n",
    "    # Avoid division by zero if the array has identical elements\n",
    "    if arr_min == arr_max:\n",
    "        return np.full_like(arr, a)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    normalized_arr = (arr - arr_min) / (arr_max - arr_min)\n",
    "    \n",
    "    # Scale to [a, b]\n",
    "    scaled_arr = a + (normalized_arr * (b - a))\n",
    "    \n",
    "    return scaled_arr\n",
    "\n",
    "def mean_channels(mask1, mask2, signal, chlist):\n",
    "    summ = 0\n",
    "    for ch in chlist:\n",
    "        summ += signal[mask1:mask2, 0, ch, 0]\n",
    "    summ /= len(chlist)\n",
    "    return summ\n",
    "\n",
    "def std_channels(mask1, mask2, signal, chlist):\n",
    "    summ = 0\n",
    "    mean = mean_channels(mask1, mask2, signal, chlist)\n",
    "    for ch in chlist:\n",
    "        summ += (signal[mask1:mask2, 0, ch, 0] - mean)**2\n",
    "    #summ = sqrt(summ)\n",
    "    summ /= len(chlist)-1\n",
    "    return summ\n",
    "\n",
    "\n",
    "def ev(tsr):\n",
    "    input_shape = tsr.data.shape\n",
    "    result_shape = (input_shape[2], input_shape[2], input_shape[1], input_shape[3])\n",
    "    result = numpy.zeros(result_shape)\n",
    "\n",
    "    for mode in range(result_shape[3]):\n",
    "        for var in range(result_shape[2]):\n",
    "            data = tsr.data[1000:,var,:, mode].squeeze()\n",
    "            result[:, :, var, mode] = numpy.corrcoef(data.T)\n",
    "\n",
    "    corr_coeff = graph.CorrelationCoefficients(source=tsr, array_data=result)\n",
    "    return corr_coeff\n",
    "\n",
    "\n",
    "def psd_matrix(time_series):\n",
    "    result = np.zeros((freq, n_regions))\n",
    "    for x in range (n_regions):\n",
    "        result[:, x] = signal.welch(time_series[:, x], freq_sample, nperseg = 10000)[1]\n",
    "    return result\n",
    "\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=1):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "freq_sample = 1024\n",
    "lowcut = 0.5\n",
    "highcut = 45\n",
    "order = 4\n",
    "\n",
    "n_seg = 2048\n",
    "freq_sample = n_seg//2\n",
    "freq = freq_sample+1 \n",
    "window = 'hamming'\n",
    "\n",
    "\n",
    "def filter_bandpass(signal, lowcut, highcut, fs):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    signal_bp = filtfilt(b, a, signal, axis = 0)\n",
    "    return signal_bp\n",
    "\n",
    "\n",
    "def compute_psd(time_series): \n",
    "    \n",
    "    signal_bp = np.zeros((len(time_series[:,0,0,0]), len(time_series[0,0,:,0])))\n",
    "\n",
    "\n",
    "    Welch_signal_bp = np.zeros((freq, freq, len(time_series[0,0,:,0])))\n",
    "    \n",
    "    for i in range (len(time_series[0,0,:,0])):\n",
    "        signal_bp[:,i] = filter_bandpass(time_series[:,0,i,0], lowcut, highcut, freq_sample)\n",
    "        Welch_signal_bp[:, 0, i], Welch_signal_bp[0, :, i] = signal.welch(signal_bp[:,i],\n",
    "                                                                                    freq_sample, nperseg=n_seg, \n",
    "                                                                                    noverlap=n_seg//2, window=window)\n",
    "        \n",
    "    \n",
    "    welch_mean = np.mean(Welch_signal_bp[0, :, :], axis = 1)\n",
    "    welch_mean /= np.max(welch_mean) #Normalize\n",
    "    welch_sem =  np.std(Welch_signal_bp[0, :, :], axis = 1)\n",
    "    welch_sem /= np.max(welch_mean) #Normalize\n",
    "    \n",
    "    return Welch_signal_bp[:, 0, 0], Welch_signal_bp[0, :, :]  #, welch_mean, welch_sem\n",
    "\n",
    "def reduce(li):\n",
    "    result = [(x+y)/2.0 for x, y in zip(li[::2], li[1::2])]\n",
    "    if len(li) % 2:\n",
    "        result.append(li[-1])\n",
    "    return result\n",
    "\n",
    "\n",
    "def binary_FC(time_series, period = 1, th = 0.13):\n",
    "    \n",
    "    con = connectivity.Connectivity.from_file('connectivity_76.zip') \n",
    "     # Build a TimeSeries Dataype.\n",
    "    tsr = TimeSeriesRegion(connectivity=con,\n",
    "                           data=time_series[:,:,:,:],                            #in TVB 4D format\n",
    "                           sample_period=period) #in ms\n",
    "    tsr.configure()\n",
    "\n",
    "\n",
    "    result_tavg = ev(tsr)\n",
    "    corr_tavg = result_tavg.array_data[..., 0, 0]\n",
    "    corr_tavg_th = corr_tavg > th\n",
    "\n",
    "\n",
    "    pmatrix = np.zeros((76,76))\n",
    "\n",
    "    for x in range(76):\n",
    "        np.nan_to_num(pmatrix[x,:], copy = False)\n",
    "        np.nan_to_num(time_series, copy = False)\n",
    "    for x in range(76):    \n",
    "        for y in range(76):\n",
    "            \n",
    "#             print(pearsonr(time_series[:,0,x,:], time_series[:,0,y,:])[1])\n",
    "            pmatrix[x][y] = pearsonr(time_series[:,0,x,:], time_series[:,0,y,:])[1]\n",
    "\n",
    "    pmatrix_th = pmatrix < 0.05\n",
    "    corr_tavg_th = np.multiply(corr_tavg_th, pmatrix_th)\n",
    "    mean_corr = corr_tavg_th.mean()\n",
    "    \n",
    "    return corr_tavg_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd9c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define impaired regions (taken from Amyloid Braak stage I)\n",
    "impaired_regions = [9, 21, 22, 30, 31, 32, 34, 59, 60, 62, 68, 69, 70, 72]\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "'''We determine model parameters as explained in the paper (eqs 3 and 4), including a neuroplasticity parameter np\n",
    "(which multiplies cp in the second row of equations 3)'''\n",
    "\n",
    "n_steps = 50 #How many steps you want to use for changing t_e and t_i\n",
    "a_array = np.linspace(0.100,0.112,n_steps) #This is the array of considered t_e values, TVB uses'a' as a parameter which is 1/t_e\n",
    "b_array = np.linspace(0.05,0.025,n_steps) #This is the array of considered t_i values, TVB uses 'b' as a parameter which is 1/t_i\n",
    "\n",
    "your_path = ''\n",
    "structural_connectivities = np.load(your_path + 'structural_connectivities.npy')\n",
    "\n",
    "#Define important constants\n",
    "simul_length = 4000 #How long the simulation is gonna be by default (at least 4000)\n",
    "def Simulate(cp, lp, np_parameter, g, velocity, noise, regions = impaired_regions, sim_time = 10000):\n",
    "    '''This function simulates signals at different levels of neurodegeneration parameters. The regions in which hypoinhibition is modelled are passed \n",
    "    through the \"regions\" argument which by default is equal to the \"impaired_regions\" listed above''' \n",
    "\n",
    "    con = connectivity.Connectivity.from_file('connectivity_76.zip') \n",
    "    con.weights = structural_connectivities[cp, np_parameter, :, :] #This alters the connectome according to equation 3 for a combination of cp and np\n",
    "    # cp is comprised between o and 2 with 50 equal steps, while neuroplasticity is uniformally distributed between 0 and 2 with steps of 0.25 amplitude (plus a value of 2.5 at the end)\n",
    "    con.weights = con.weights / np.max(con.weights)              #normalised by maximum weight  \n",
    "    con.weights *= g\n",
    "    con.speed = np.array(velocity)                               #To select conduction velocity of the signal\n",
    "    con.configure()\n",
    "    \n",
    "    a_value = a_array[lp] #this determines the value of t_e\n",
    "    b_value = b_array[lp] #this determines the value of t_i\n",
    "\n",
    "    #altering inhibition in impaired regions:\n",
    "    b_regions = np.ones(76)*0.05 #default value\n",
    "    b_regions [regions]  = np.ones(len(regions)) * b_value # impairs b value (and therefore t_i) only in selected regions\n",
    "\n",
    "\n",
    "    # setup model based on paper's parameters\n",
    "    model_pars = dict(\n",
    "        A=3.25, #excitatory PSP\n",
    "        B=22, #inhibitory PSP\n",
    "        v0=6.0,\n",
    "        a=a_value, # increased with respect to the healthy case. (also remember that TVB uses ms, not s)\n",
    "        b=b_regions,    # decreased with respect to the healthy case. (also remember that TVB uses ms, not s)\n",
    "        r=0.56,\n",
    "        nu_max=0.0025, # e0 in the JR original paper\n",
    "        # TVB factors C_i into J*a_i, e.g. C1 = a_1 * J\n",
    "        J=128,\n",
    "        a_1=1.0,\n",
    "        a_2=0.8,\n",
    "        a_3= 0.25,\n",
    "        a_4= 0.25,\n",
    "        mu=0.22, # baseline input, avg of 120 and 320 pulses/s\n",
    "    )\n",
    "\n",
    "    # implement JR + afferent PSP for setting the JR in the right portion of the phase space\n",
    "    class JRPSP(tvb.models.JansenRit):\n",
    "        state_variable_range = Final(\n",
    "            default={\"y0\": np.array([-1.0, 1.0]),\n",
    "                     \"y1\": np.array([-500.0, 500.0]),\n",
    "                     \"y2\": np.array([-50.0, 50.0]),\n",
    "                     \"y3\": np.array([-6.0, 6.0]),\n",
    "                     \"y4\": np.array([-20.0, 20.0]),\n",
    "                     \"y5\": np.array([-500.0, 500.0]),\n",
    "                     \"y6\": np.array([-20.0, 20.0]),\n",
    "                     \"y7\": np.array([-500.0, 500.0])})\n",
    "\n",
    "        variables_of_interest = List(\n",
    "            of=str,\n",
    "            label=\"Variables watched by Monitors\",\n",
    "            choices=(\"y0\", \"y1\", \"y2\", \"y3\", \"y4\", \"y5\", \"y6\", \"y7\"),\n",
    "            default=(\"y0\", \"y1\", \"y2\", \"y3\"))\n",
    "\n",
    "        state_variables = tuple('y0 y1 y2 y3 y4 y5 y6 y7'.split())\n",
    "        _nvar = 8\n",
    "        cvar = np.array([6], dtype=np.int32)\n",
    "\n",
    "        def dfun(self, state_variables, coupling, local_coupling=0.0):\n",
    "            dy = np.zeros((8, state_variables.shape[1], 1))\n",
    "            # TVB's JR is eq 6 only\n",
    "            dy[:6] = super().dfun(state_variables[:6], coupling, local_coupling)\n",
    "            # tack on PSP for efferent following eq 8\n",
    "            # NB with this, only y12 is coupling var for TVB\n",
    "            y0, y1, y2, y3, y4, y5, y6, y7 = state_variables\n",
    "            a_d = self.a / 3.0\n",
    "            sigm_y1_y2 = 2.0 * self.nu_max / (1.0 + np.exp(self.r * (self.v0 - (y1 - y2))))\n",
    "            dy[6] = y7\n",
    "            dy[7] = self.A * a_d * sigm_y1_y2 - 2.0 * a_d * y7 - self.a**2 * y6\n",
    "            return dy\n",
    "\n",
    "    # factor out noise from dy4 = A a (p(t) + ...) as y4 += dt (...) + A a dW_t\n",
    "    # this allows us to model the noise as TVB does it, though scaling requires experiment\n",
    "    nsig = np.zeros((8, 76, 1))\n",
    "    nsig[4] = model_pars['A'] * model_pars['a'] * (.320 - .120) * noise\n",
    "    noise = tvb.noise.Additive(nsig=nsig)\n",
    "\n",
    "    #setting up monitors:\n",
    "    period = 1. #sampling time in terms of simulation time (total number of timepoints = sim_time / period)\n",
    "    mon_tavg = monitors.TemporalAverage(period=period)\n",
    "    mon_EEG = monitors.EEG.from_file(sensors_fname='eeg_brainstorm_65.txt', \n",
    "                                                                  projection_fname='projection_eeg_65_surface_16k.npy',\n",
    "                                                                  rm_f_name='regionMapping_16k_76.txt',\n",
    "                                                                  period=period\n",
    "                                                                  )\n",
    "    \n",
    "    #Bundling\n",
    "    what_to_watch = (mon_tavg, mon_EEG)\n",
    "    \n",
    "\n",
    "    sim = simulator.Simulator(connectivity=con,\n",
    "                              conduction_speed=np.float(con.speed),\n",
    "                              model=JRPSP(\n",
    "                              variables_of_interest=(\"y0\", \"y1\", \"y2\", \"y3\", \"y4\", \"y5\", \"y6\", \"y7\"),\n",
    "                              **{k: np.array(v) for k, v in model_pars.items()}),\n",
    "                              coupling=tvb.coupling.Sigmoidal(a=np.array([10.0])),\n",
    "                              integrator=tvb.integrators.EulerStochastic(dt=0.1, noise=noise),\n",
    "                              monitors=what_to_watch,\n",
    "                              simulation_length=sim_time)\n",
    "    sim.configure()\n",
    "\n",
    "    (ttavg, tavg), (teeg, eeg) = sim.run(simulation_length=sim_time) #tavg is the name of signals in region space\n",
    "\n",
    "    return ttavg, tavg, teeg, eeg # ttavg and teeg are the timestamps\n",
    "\n",
    "\n",
    "def preprocess(ttavg, tavg, teeg, eeg, PSD = True, normalize = True, cut = 1000):\n",
    "\n",
    "    \n",
    "    if PSD:\n",
    "        #Discarding initial transient for PSD analysis\n",
    "        ttavg = ttavg[cut:]\n",
    "        tavg = tavg[cut:, :, :, :]\n",
    "                           \n",
    "        teeg = teeg[cut:]\n",
    "        eeg = eeg[cut:, :, :, :]\n",
    "        \n",
    "        ttavg -= cut\n",
    "        teeg -= cut\n",
    "        \n",
    "\n",
    "    if normalize:\n",
    "        #Normalizing and subtracting average\n",
    "        tavg /= (np.max(tavg,0) - np.min(tavg,0 ))\n",
    "        tavg -= np.mean(tavg, 0)\n",
    "        eeg /= (np.max(eeg,0) - np.min(eeg,0 ))\n",
    "        eeg -= np.mean(eeg, 0)\n",
    "                           \n",
    "    return ttavg, tavg, teeg, eeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b756d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First grid search to identify values of structural quantities (these will not be altered by the disease parameters\n",
    "global_coupling_val = [0.1,1,10]\n",
    "velocity_val = [1,10,np.inf]\n",
    "noise_val = [50e-7, 50e-3, 5]\n",
    "\n",
    "n_regions = len(connectivity.Connectivity.from_file('connectivity_76.zip').weights) #Standard TVB connectome\n",
    "n_channels = 65\n",
    "\n",
    "tavgs = np.zeros((len(global_coupling_val), len(velocity_val), len(noise_val), simul_length, n_regions))\n",
    "eegs = np.zeros((len(global_coupling_val), len(velocity_val), len(noise_val), simul_length, n_channels))\n",
    "\n",
    "for i in range(len(global_coupling_val)):\n",
    "    for j in range(len(velocity_val)):\n",
    "        for k in range(len(noise_val)):\n",
    "            ttavg, tavg, teeg, eeg = Simulate(cp = 0, lp = 0, np_parameter = 0, g=global_coupling_val[i],\n",
    "                                                              velocity=velocity_val[j], noise=noise_val[k], sim_time = simul_length)\n",
    "#             ttavg, tavg_healthy, teeg, eeg_healthy = preprocess(ttavg, tavg_healthy, teeg, eeg_healthy) #if you want to preprocess\n",
    "                                                                                                          \n",
    "            tavgs[i,j,k,:,:] = tavg[:, 0, :, 0]\n",
    "            eegs[i,j,k,:,:] = eeg[:, 0, :, 0]\n",
    "            \n",
    "#Here insert your check to identify best combination (or simply visually check as in \"AD_model_simulations\" and code below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7170d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visual checking the best solution in terms of global coupling, velocity, noise\n",
    "# dimensions of eegs are [global coupling, velocity, noise, time, channels]\n",
    "\n",
    "# eeg = eegs[0,2,2, 1000:, :]\n",
    "\n",
    "# eeg /= (np.max(eeg,0) - np.min(eeg,0 )) #normalization step\n",
    "# eeg -= np.mean(eeg, 0)  #re-referencing step\n",
    "\n",
    "# teeg = np.linspace(0,np.shape(eeg)[0], np.shape(eeg)[0]) #creating an array of time-steps\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,12))\n",
    "# plt.plot(teeg, eeg + np.r_[:len(mon_EEG.sensors.labels)]) # the np.r_[:76] is addedd to separate channels or regions\n",
    "# plt.yticks(np.r_[:len(mon_EEG.sensors.labels)], mon_EEG.sensors.labels, fontsize = 12)\n",
    "# plt.title(\"Brain activity (EEG) \", fontsize = 18)\n",
    "# plt.xlabel('time (ms)', fontsize = 16)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second grid search to identify digital biomarkers\n",
    "psd_array = np.zeros((n_steps,n_steps,n_steps,91, n_regions))\n",
    "FC_array = np.zeros((n_steps,n_steps,n_steps,n_regions,n_regions))\n",
    "\n",
    "mean_FCs = np.zeros((n_steps, n_steps, n_steps))\n",
    "mean_PSD_alphas = np.zeros((n_steps, n_steps, n_steps))\n",
    "\n",
    "#Here we simulate signals and compute digital biomarkers from virtual patients\n",
    "\n",
    "###########################################################\n",
    "for i in range(n_steps):\n",
    "    for j in range(50):      # the SC matrices here uploaded consider 50 values for cp and 10 for np, if you need more use equations 2 and 3\n",
    "        for k in range(10):  # from the paper (DOI: https://www.doi.org/10.1186/s13195-025-01718-6) considering additional values\n",
    "        \n",
    "            # Suppose that at the previous step the optimal parameter combination was global_coupling_val[0], velocity_val[0], noise=noise_val[0]\n",
    "            ttavg, tavg, teeg, eeg = Simulate(cp = i, lp = j, np_parameter = k, g=global_coupling_val[0],\n",
    "                                             velocity=velocity_val[0], noise=noise_val[0], sim_time = simul_length)\n",
    "\n",
    "            ttavg, tavg, teeg, eeg = preprocess(ttavg, tavg, teeg, eeg)\n",
    "            print(np.shape(tavg))\n",
    "\n",
    "\n",
    "            freqs_tavg, Welch_tavg = compute_psd(tavg)\n",
    "\n",
    "            psd_array[i,j,k,:,:] = Welch_tavg[:91, :] #This stores the PSD\n",
    "            FC_array[i,j,k,:,:] = binary_FC(tavg) #This stores the FC\n",
    "\n",
    "            mean_PSD_alphas[i,j,k] = np.sum(psd_array[i,j,k, 16:26, :].mean(axis=1)) / np.sum(psd_array[i,j,k, :, :].mean(axis=1)) #Compute relative alpha power\n",
    "            mean_FCs[i,j,k] = psd_array[i,j,k, :, :].mean() #Compute average FC\n",
    "\n",
    "            print(i*n_steps**2 + j*n_steps + k) #Checks the current step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
